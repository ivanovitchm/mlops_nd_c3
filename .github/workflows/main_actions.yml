# This is a basic workflow to help you get started with Actions

name: CI

# Controls when the workflow will run
on:
  # Triggers the workflow on push or pull request events but only for the main branch
  push:
    branches: [ main ]

# A workflow run is made up of one or more jobs that can run sequentially or in parallel
jobs:
  # This workflow contains a single job called "build"
  build:
    # The type of runner that the job will run on
    runs-on: macos-latest

    # Steps represent a sequence of tasks that will be executed as part of the job
    steps:
      # Checks-out your repository under $GITHUB_WORKSPACE, so your job can access it
      - uses: actions/checkout@v2
      
      # Set up DVC in the action 
      - uses: iterative/setup-dvc@v1
      
      # Configure AWS Secrets
      - name: Configure AWS Credentials
        uses: aws-actions/configure-aws-credentials@v1
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: us-east-1
      
      - name: Setup Python
        uses: actions/setup-python@v3.0.0
        with:
          # Version range or exact version of a Python version to use, using SemVer's version range syntax.
          python-version: 3.8
      
      - name: Install dependences
        run: pip install --upgrade pip && pip install -r requirements.txt
          
      - name: Code quality authority
        run: |
          # if Python syntax errors or undefined names occur, stop the build process.
          python3.8 -m flake8 . --count --select=E9,F63,F7,F82 --show-source --statistics
          # exit-zero treats all errors as warnings. The GitHub editor is 127 chars wide
          python3.8 -m flake8 . --ignore=E402 --count --exit-zero --max-complexity=10 --max-line-length=127 --statistics
      
      - name: Pull DVC data
        run:
          dvc pull -r s3remote
          
      - name: Build and Install
        run: |
          # dependency of xgboost in macos system
          brew install libomp
      
      - name: Testing data and model
        run: |
          # apply deterministic and non-deterministic test to the preprocessing_data.csv
          pytest pipeline/check_data -s -vv --sample_artifact pipeline/data/preprocessing_data.csv \
                                             --param params.yaml
          # unit tests to evaluate if any ML functions return the expected type
          pytest pipeline/check_model -s -vv --test_data pipeline/data/test_data.csv \
                                        --model pipeline/data/model_export \
                                        --encoder pipeline/data/encoder_export
